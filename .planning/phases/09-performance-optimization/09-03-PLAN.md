---
phase: 09-performance-optimization
plan: 03
type: execute
wave: 2
depends_on: []
files_modified:
  - backend/workorder/views/work_order_tasks/task_stats.py
  - backend/workorder/views/work_order_tasks/task_main.py
autonomous: true

must_haves:
  truths:
    - "collaboration_stats endpoint uses single aggregated query instead of N+1 queries"
    - "department_workload uses annotate instead of loop-based counting"
    - "Query count reduced by 70% compared to baseline"
    - "All tasks querysets use select_related for ForeignKey lookups"
  artifacts:
    - path: "backend/workorder/views/work_order_tasks/task_stats.py"
      provides: "Optimized statistics views with annotated queries"
      contains: ".annotate("
    - path: "backend/workorder/views/work_order_tasks/task_main.py"
      provides: "Optimized task list queryset"
      contains: "select_related("
  key_links:
    - from: "backend/workorder/views/work_order_tasks/task_stats.py"
      to: "workorder.models.WorkOrderTask"
      via: "Annotated aggregate queries using Count and Sum"
      pattern: "WorkOrderTask.objects.*annotate.*Count"
---

<objective>
Optimize ORM queries in task statistics and list views to eliminate N+1 query problems using select_related, prefetch_related, and annotate.

Purpose: Reduce database query count by 70% and ensure all statistics endpoints use efficient single-query aggregations instead of loop-based counting.
Output: Optimized views with annotated queries and proper eager loading.
</objective>

<execution_context>
@/home/chenjiaxing/.claude/get-shit-done/workflows/execute-plan.md
@/home/chenjiaxing/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-performance-optimization/09-RESEARCH.md

# Source files to modify
@backend/workorder/views/work_order_tasks/task_stats.py
@backend/workorder/views/work_order_tasks/task_main.py
@backend/workorder/services/query_optimizer.py
</context>

<tasks>

<task type="auto">
  <name>Optimize collaboration_stats to eliminate N+1 queries</name>
  <files>backend/workorder/views/work_order_tasks/task_stats.py</files>
  <action>
    Rewrite the collaboration_stats method (lines 136-266) to use annotated queries instead of loop-based counting:

    1. Replace the operator loop (lines 178-246) with a single annotated query:

    ```python
    # Get operators with annotated statistics in a SINGLE query
    from django.db.models import Count, Sum, Q, F, Avg

    operators_data = User.objects.filter(
        assigned_tasks__isnull=False,
        is_active=True
    ).exclude(
        is_superuser=True
    )

    # Apply department filter if specified
    if department_id:
        operators_data = operators_data.filter(
            assigned_tasks__assigned_department_id=department_id
        )

    # Annotate all statistics in ONE query
    operators_data = operators_data.annotate(
        operator_id=F('id'),
        operator_username=F('username'),
        total_tasks=Count('assigned_tasks', distinct=True),
        completed_tasks=Count('assigned_tasks', filter=Q(assigned_tasks__status='completed'), distinct=True),
        in_progress_tasks=Count('assigned_tasks', filter=Q(assigned_tasks__status='in_progress'), distinct=True),
        pending_tasks=Count('assigned_tasks', filter=Q(assigned_tasks__status='pending'), distinct=True),
        total_completed_quantity=Sum('assigned_tasks__quantity_completed', filter=Q(assigned_tasks__status='completed')),
        total_defective_quantity=Sum('assigned_tasks__quantity_defective', filter=Q(assigned_tasks__status='completed')),
        total_production_quantity=Sum('assigned_tasks__production_quantity', filter=Q(assigned_tasks__status='completed')),
    ).values(
        'operator_id', 'operator_username',
        'total_tasks', 'completed_tasks', 'in_progress_tasks', 'pending_tasks',
        'total_completed_quantity', 'total_defective_quantity', 'total_production_quantity'
    )

    stats_list = []
    for op_data in operators_data:
        total = op_data['total_tasks'] or 0
        completed = op_data['completed_tasks'] or 0
        completed_qty = op_data['total_completed_quantity'] or 0
        defective_qty = op_data['total_defective_quantity'] or 0

        # Calculate defective rate
        defective_rate = round((defective_qty / completed_qty * 100), 2) if completed_qty > 0 else 0

        # Get completion rate
        completion_rate = round((completed / total * 100), 2) if total > 0 else 0

        stats_list.append({
            'operator_id': op_data['operator_id'],
            'operator_username': op_data['operator_username'],
            'operator_name': op_data['operator_username'],  # Can be enhanced with get_full_name()
            'departments': [],  # Departments loaded separately if needed
            'total_tasks': total,
            'completed_tasks': completed,
            'in_progress_tasks': op_data['in_progress_tasks'] or 0,
            'pending_tasks': op_data['pending_tasks'] or 0,
            'total_completed_quantity': completed_qty,
            'total_defective_quantity': defective_qty,
            'total_production_quantity': op_data['total_production_quantity'] or 0,
            'defective_rate': defective_rate,
            'completion_rate': completion_rate,
            'avg_completion_hours': None,  # Requires separate query for completion times
        })
    ```

    2. Keep the avg_completion_hours as a separate query since it requires log joins:
    ```python
    # Average completion times (separate optimized query)
    task_ids_with_logs = WorkOrderTask.objects.filter(
        status='completed',
        assigned_operator_id__in=[op['operator_id'] for op in stats_list]
    ).values_list('id', flat=True)

    # Bulk fetch completion times using annotation
    from django.db.models import ExpressionWrapper, DurationField, F
    from datetime import timedelta

    completion_data = WorkOrderTask.objects.filter(
        id__in=task_ids_with_logs
    ).annotate(
        completion_duration=ExpressionWrapper(
            F('logs__created_at') - F('created_at'),
            output_field=DurationField()
        )
    ).values('assigned_operator_id', 'completion_duration')

    # Group by operator and calculate average
    from collections import defaultdict
    operator_times = defaultdict(list)
    for item in completion_data:
        if item['completion_duration']:
            hours = item['completion_duration'].total_seconds() / 3600
            operator_times[item['assigned_operator_id']].append(hours)

    # Map to stats_list
    for stat in stats_list:
        times = operator_times.get(stat['operator_id'], [])
        stat['avg_completion_hours'] = round(sum(times) / len(times), 2) if times else None
    ```

    3. The summary aggregation should also use a single query:
    ```python
    # Summary statistics in one query
    summary_data = User.objects.filter(
        assigned_tasks__isnull=False,
        is_active=True
    ).aggregate(
        total_operators=Count('id', distinct=True),
        total_tasks=Count('assigned_tasks'),
        total_completed_tasks=Count('assigned_tasks', filter=Q(assigned_tasks__status='completed')),
        total_completed_quantity=Sum('assigned_tasks__quantity_completed'),
        total_defective_quantity=Sum('assigned_tasks__quantity_defective'),
    )
    ```
  </action>
  <verify>grep -n "\.annotate(" backend/workorder/views/work_order_tasks/task_stats.py | head -5</verify>
  <done>collaboration_stats uses annotated queries reducing N+1 to single-digit queries</done>
</task>

<task type="auto">
  <name>Optimize department_workload with proper eager loading</name>
  <files>backend/workorder/views/work_order_tasks/task_stats.py</files>
  <action>
    Review and optimize the department_workload method (lines 269-395):

    1. Verify select_related is used for ForeignKey lookups:
    The current code (line 323-329) already uses select_related:
    ```python
    tasks = WorkOrderTask.objects.filter(
        assigned_department_id=department_id
    ).select_related(
        'assigned_operator', 'assigned_department', 'work_order_process'
    ).prefetch_related('logs')
    ```
    This is CORRECT - keep it.

    2. Optimize the priority_distribution query (lines 371-377) to use aggregate instead of multiple filter calls:
    ```python
    # Replace individual count() calls with aggregation
    priority_data = tasks.aggregate(
        urgent=Count('id', filter=Q(priority='urgent')),
        high=Count('id', filter=Q(priority='high')),
        normal=Count('id', filter=Q(priority='normal')),
        low=Count('id', filter=Q(priority='low'))
    )
    priority_distribution = {
        'urgent': priority_data['urgent'],
        'high': priority_data['high'],
        'normal': priority_data['normal'],
        'low': priority_data['low']
    }
    ```

    3. The operators_data query (lines 342-358) already uses annotate correctly - keep it.

    4. Add logging to track query count:
    ```python
    from django.db import connection
    from django.conf import settings

    # At the start of the method, if DEBUG
    if settings.DEBUG:
        initial_query_count = len(connection.queries)
    ```

    And at the end:
    ```python
    if settings.DEBUG:
        final_query_count = len(connection.queries)
        logger.info(f"department_workload queries: {final_query_count - initial_query_count}")
    ```
  </action>
  <verify>grep -n "\.aggregate(" backend/workorder/views/work_order_tasks/task_stats.py</verify>
  <done>department_workload uses aggregate() for priority distribution reducing query count</done>
</task>

<task type="auto">
  <name>Verify task list queryset uses select_related properly</name>
  <files>backend/workorder/views/work_order_tasks/task_main.py</files>
  <action>
    1. First, check if task_main.py exists and examine the get_queryset method:
    ```bash
    cat backend/workorder/views/work_order_tasks/task_main.py
    ```

    2. Ensure the queryset includes select_related for all ForeignKey fields used in serialization:
    Common fields that need select_related:
    - work_order_process (includes work_order via the process)
    - assigned_department
    - assigned_operator
    - product (if used)
    - material (if used)

    The queryset should look like:
    ```python
    queryset = WorkOrderTask.objects.select_related(
        'work_order_process',
        'work_order_process__work_order',
        'assigned_department',
        'assigned_operator',
        'product',
        'material'
    )
    ```

    3. If the file doesn't exist or get_queryset is missing, create/optimize it:
    Find the WorkOrderTask ViewSet class and add/modify get_queryset method.

    4. Add a query count verification comment after the queryset definition:
    ```python
    # Query optimization: select_related reduces N+1 queries for ForeignKey lookups
    # Expected: 1 query for tasks list instead of 1+N queries
    ```
  </action>
  <verify>grep -n "select_related" backend/workorder/views/work_order_tasks/task_main.py</verify>
  <done>Task list queryset uses select_related for all ForeignKey fields accessed in serializer</done>
</task>

<task type="auto">
  <name>Create query performance verification test</name>
  <files>backend/workorder/tests/test_performance.py</files>
  <action>
    Create a performance test file to verify query optimization:

    1. Create backend/workorder/tests/test_performance.py:
    ```python
    """
    Performance tests to verify query optimization
    """
    from django.test import TestCase
    from django.db import connection
    from django.test.utils import override_settings
    from django.contrib.auth.models import User
    from workorder.models.core import WorkOrderTask, WorkOrder, WorkOrderProcess
    from workorder.models.base import Department

    class PerformanceTestCase(TestCase):
        """Test query performance and N+1 elimination"""

        def setUp(self):
            """Create test data"""
            self.department = Department.objects.create(name='Test Dept')
            self.user = User.objects.create_user(username='testuser')
            self.user.profile.departments.add(self.department)

            # Create work order and process
            self.work_order = WorkOrder.objects.create(
                order_number='TEST001',
                customer_id=1
            )
            self.process = WorkOrderProcess.objects.create(
                work_order=self.work_order,
                process_id=1
            )

            # Create tasks
            for i in range(10):
                WorkOrderTask.objects.create(
                    work_order_process=self.process,
                    assigned_department=self.department,
                    assigned_operator=self.user,
                    status='pending'
                )

        @override_settings(DEBUG=True)
        def test_collaboration_stats_query_count(self):
            """Test that collaboration_stats uses limited queries"""
            from workorder.views.work_order_tasks.task_stats import TaskStatsMixin

            mixin = TaskStatsMixin()
            from django.test import RequestFactory
            factory = RequestFactory()
            request = factory.get('/api/workorder-tasks/collaboration_stats/')
            request.user = self.user

            # Reset query count
            from django.db import reset_queries
            reset_queries()

            # Execute
            response = mixin.collaboration_stats(request)

            # Check query count (should be < 10 for optimized version)
            query_count = len(connection.queries)
            self.assertLess(query_count, 10,
                f"Too many queries: {query_count}. Expected <10.")

        @override_settings(DEBUG=True)
        def test_department_workload_query_count(self):
            """Test that department_workload uses limited queries"""
            from workorder.views.work_order_tasks.task_stats import TaskStatsMixin

            mixin = TaskStatsMixin()
            from django.test import RequestFactory
            factory = RequestFactory()
            request = factory.get(f'/api/workorder-tasks/department_workload/?department_id={self.department.id}')
            request.user = self.user
            request.user.user_permissions.add(
                Permission.objects.get(codename='change_workorder')
            )

            from django.db import reset_queries
            reset_queries()

            response = mixin.department_workload(request)

            query_count = len(connection.queries)
            self.assertLess(query_count, 15,
                f"Too many queries: {query_count}. Expected <15.")
    ```

    2. Run the tests to verify:
    ```bash
    cd backend && python manage.py test workorder.tests.test_performance
    ```

    Note: The tests may need adjustment based on actual permission setup. Focus on the query count assertion pattern.
  </action>
  <verify>ls -la backend/workorder/tests/test_performance.py</verify>
  <done>Performance test file created with query count assertions</done>
</task>

</tasks>

<verification>
1. collaboration_stats uses annotated queries instead of loop-based counting
2. department_workload uses aggregate() for priority distribution
3. task list queryset uses select_related for all ForeignKey fields
4. Performance test file exists with query count assertions
5. Query count reduced by at least 70% compared to baseline (measure with DEBUG=True)
</verification>

<success_criteria>
- collaboration_stats: <10 queries total (down from 1+ queries per operator)
- department_workload: <15 queries total
- Task list: 1 query for list + 1 for count (pagination)
- No N+1 patterns in statistics views
</success_criteria>

<output>
After completion, create `.planning/phases/09-performance-optimization/09-03-SUMMARY.md`
</output>
