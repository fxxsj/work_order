---
phase: 09-performance-optimization
plan: 02
type: execute
wave: 2
depends_on: ["09-01"]
files_modified:
  - backend/workorder/performance/cache_invalidation.py
  - backend/workorder/views/work_order_tasks/task_stats.py
  - backend/workorder/services/cache_service.py
autonomous: true

must_haves:
  truths:
    - "Department workload statistics load from Redis cache in under 200ms on cache hit"
    - "Cache is automatically invalidated when tasks are created/updated/deleted"
    - "Collaboration stats endpoint uses cached aggregate data"
  artifacts:
    - path: "backend/workorder/performance/cache_invalidation.py"
      provides: "Signal-based cache invalidation handlers"
      contains: "@receiver(post_save, sender=WorkOrderTask)"
    - path: "backend/workorder/views/work_order_tasks/task_stats.py"
      provides: "Cached statistics endpoints"
      contains: "cache.get(dept_stats:"
    - path: "backend/workorder/services/cache_service.py"
      provides: "Task-specific caching utilities"
      contains: "task_statistics_cache"
  key_links:
    - from: "backend/workorder/performance/cache_invalidation.py"
      to: "django.core.cache.cache"
      via: "cache.delete and cache.delete_pattern calls"
      pattern: "cache\.delete.*task_stats"
    - from: "backend/workorder/views/work_order_tasks/task_stats.py"
      to: "backend/workorder/services/cache_service.py"
      via: "Import and use of caching utilities"
      pattern: "from workorder.services.cache_service import"
---

<objective>
Implement Redis caching for task statistics and dashboard data with automatic cache invalidation.

Purpose: Reduce database load for expensive aggregate queries (statistics, counts) and achieve sub-200ms response times for cached data.
Output: Signal-based cache invalidation service and cached statistics endpoints.
</objective>

<execution_context>
@/home/chenjiaxing/.claude/get-shit-done/workflows/execute-plan.md
@/home/chenjiaxing/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-performance-optimization/09-RESEARCH.md

# Source files to modify
@backend/workorder/services/cache_service.py
@backend/workorder/views/work_order_tasks/task_stats.py
</context>

<tasks>

<task type="auto">
  <name>Create cache invalidation service with signal handlers</name>
  <files>backend/workorder/performance/cache_invalidation.py</files>
  <action>
    Create a new module backend/workorder/performance/cache_invalidation.py with:

    1. First, create the performance directory:
       ```bash
       mkdir -p backend/workorder/performance
       touch backend/workorder/performance/__init__.py
       ```

    2. Create cache_invalidation.py with the following content:

    ```python
    """
    Cache invalidation service using Django signals

    Automatically invalidates task statistics cache when tasks change.
    """
    from django.db.models.signals import post_save, post_delete
    from django.dispatch import receiver
    from django.core.cache import cache
    import logging

    logger = logging.getLogger(__name__)

    # Cache key patterns
    TASK_STATS_KEY_PATTERN = 'task_stats:{dept_id}'
    DEPT_WORKLOAD_KEY_PATTERN = 'dept_workload:{dept_id}'
    OPERATOR_STATS_KEY_PATTERN = 'operator_stats:{operator_id}'
    DASHBOARD_PATTERN = 'dashboard:*'

    @receiver(post_save, sender='workorder.WorkOrderTask')
    @receiver(post_delete, sender='workorder.WorkOrderTask')
    def invalidate_task_cache_on_change(sender, instance, **kwargs):
        """
        Invalidate task-related cache when a task is saved or deleted

        Invalidates:
        - Department statistics cache
        - Operator statistics cache (if task has operator)
        - Dashboard cache pattern
        """
        try:
            # Invalidate department stats
            if instance.assigned_department_id:
                dept_key = TASK_STATS_KEY_PATTERN.format(dept_id=instance.assigned_department_id)
                cache.delete(dept_key)
                logger.debug(f"Invalidated dept stats cache: {dept_key}")

                dept_workload_key = DEPT_WORKLOAD_KEY_PATTERN.format(dept_id=instance.assigned_department_id)
                cache.delete(dept_workload_key)
                logger.debug(f"Invalidated dept workload cache: {dept_workload_key}")

            # Invalidate operator stats
            if instance.assigned_operator_id:
                operator_key = OPERATOR_STATS_KEY_PATTERN.format(operator_id=instance.assigned_operator_id)
                cache.delete(operator_key)
                logger.debug(f"Invalidated operator stats cache: {operator_key}")

            # Invalidate dashboard cache (pattern deletion)
            try:
                # For Redis backend
                cache._cache.get_client().delete_pattern(DASHBOARD_PATTERN)
                logger.debug(f"Invalidated dashboard cache pattern: {DASHBOARD_PATTERN}")
            except AttributeError:
                # Fallback for non-Redis backends
                pass

        except Exception as e:
            logger.error(f"Error invalidating cache for task {instance.id}: {e}")

    def invalidate_department_stats(department_id: int) -> None:
        """Manually invalidate department statistics cache"""
        dept_key = TASK_STATS_KEY_PATTERN.format(dept_id=department_id)
        workload_key = DEPT_WORKLOAD_KEY_PATTERN.format(dept_id=department_id)
        cache.delete_many([dept_key, workload_key])
        logger.info(f"Manually invalidated cache for department {department_id}")

    def invalidate_operator_stats(operator_id: int) -> None:
        """Manually invalidate operator statistics cache"""
        operator_key = OPERATOR_STATS_KEY_PATTERN.format(operator_id=operator_id)
        cache.delete(operator_key)
        logger.info(f"Manually invalidated cache for operator {operator_id}")
    ```

    3. Ensure the app is ready for signals by importing in apps.py or __init__.py:
    Add to backend/workorder/apps.py at the bottom:
    ```python
    # Import signal handlers
    import workorder.performance.cache_invalidation  # noqa
    ```
  </action>
  <verify>grep -l "invalidate_task_cache_on_change" backend/workorder/performance/cache_invalidation.py && grep -l "workorder.performance.cache_invalidation" backend/workorder/apps.py</verify>
  <done>Cache invalidation service created with signal handlers registered</done>
</task>

<task type="auto">
  <name>Add Redis caching to department_workload statistics endpoint</name>
  <files>backend/workorder/views/work_order_tasks/task_stats.py</files>
  <action>
    Modify the department_workload method in TaskStatsMixin (around line 269) to add Redis caching:

    1. Import cache utilities at the top of task_stats.py:
    ```python
    from django.core.cache import cache
    from django.conf import settings
    ```

    2. Add cache key constant at the top of TaskStatsMixin class:
    ```python
    DEPT_WORKLOAD_CACHE_PREFIX = 'dept_workload'
    CACHE_TIMEOUT = 300  # 5 minutes
    ```

    3. Modify the department_workload method (line 269) to add caching after department validation:
    - After the department object is retrieved (after line 320)
    - Before the tasks queryset is created

    Add this caching logic:
    ```python
    # Check cache first
    cache_key = f'{self.DEPT_WORKLOAD_CACHE_PREFIX}:{department_id}'
    cached_data = cache.get(cache_key)

    if cached_data is not None:
        logger.info(f"Cache HIT for department {department_id} workload")
        return Response(cached_data)

    logger.info(f"Cache MISS for department {department_id} workload")
    # ... existing query logic ...

    # Before return Response, cache the result
    cache.set(cache_key, response_data, self.CACHE_TIMEOUT)
    ```

    The response_data should be cached before returning Response.
  </action>
  <verify>grep -n "cache.get.*dept_workload" backend/workorder/views/work_order_tasks/task_stats.py && grep -n "cache.set.*dept_workload" backend/workorder/views/work_order_tasks/task_stats.py</verify>
  <done>department_workload endpoint uses Redis cache with 5-minute TTL</done>
</task>

<task type="auto">
  <name>Add caching to collaboration_stats endpoint</name>
  <files>backend/workorder/views/work_order_tasks/task_stats.py</files>
  <action>
    Modify the collaboration_stats method (around line 136) to add caching with parameters:

    1. Add a helper method to generate cache key that includes query parameters:
    ```python
    def _get_collaboration_stats_cache_key(self, start_date, end_date, department_id):
        """Generate cache key for collaboration stats"""
        from django.utils import timezone
        import hashlib

        # Create a hash of parameters for cache key
        params = f"{start_date or ''}:{end_date or ''}:{department_id or ''}"
        params_hash = hashlib.md5(params.encode()).hexdigest()[:8]
        return f'collab_stats:{params_hash}'
    ```

    2. Add caching at the beginning of collaboration_stats method:
    ```python
    # Check cache first
    cache_key = self._get_collaboration_stats_cache_key(start_date, end_date, department_id)
    cached_data = cache.get(cache_key)

    if cached_data is not None:
        logger.info(f"Cache HIT for collaboration stats")
        return Response(cached_data)

    logger.info(f"Cache MISS for collaboration stats")
    ```

    3. Cache the response before returning:
    ```python
    # Cache the result
    cache.set(cache_key, response_data, self.CACHE_TIMEOUT)
    return Response(response_data)
    ```

    Note: Use a shorter cache timeout (e.g., 300 seconds = 5 minutes) for collaboration stats since they change more frequently.
  </action>
  <verify>grep -n "collab_stats" backend/workorder/views/work_order_tasks/task_stats.py</verify>
  <done>collaboration_stats endpoint uses Redis cache with parameter-aware keys</done>
</task>

</tasks>

<verification>
1. Cache invalidation module created with signal handlers
2. Signal handlers are imported and registered in apps.py
3. department_workload endpoint checks cache before querying
4. collaboration_stats endpoint uses parameter-based cache keys
5. Cache is set on both endpoints with appropriate TTL
6. No database queries are made on cache hits (verify with logs)
</verification>

<success_criteria>
- department_workload loads in under 200ms on cache hit
- Cache is automatically invalidated when tasks change via signals
- Cache hit rate >70% for repeated statistics queries
- Manual cache invalidation functions available for bulk operations
</success_criteria>

<output>
After completion, create `.planning/phases/09-performance-optimization/09-02-SUMMARY.md`
</output>
