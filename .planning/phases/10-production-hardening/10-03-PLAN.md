---
phase: 10-production-hardening
plan: 03
type: execute
wave: 2
depends_on: [10-01]
files_modified:
  - backend/requirements.txt
  - backend/locust/locustfile.py
  - backend/locust/locust_config.py
  - backend/deployment/gunicorn.conf.py
  - backend/deployment/systemd/gunicorn.service
  - backend/deployment/systemd/daphne.service
  - backend/config/settings/production.py
  - deployment/nginx.conf
  - deployment/prometheus.yml
  - deployment/scripts/backup.sh
  - deployment/crontab/backup
  - backend/.prometheus.py
  - .github/workflows/load-test.yml
autonomous: true

must_haves:
  truths:
    - "Locust load test simulates 100+ concurrent users successfully"
    - "API response times remain under 500ms at target load"
    - "Error rate stays below 0.1% during load testing"
    - "Gunicorn + Daphne configuration is production-ready"
    - "Nginx reverse proxy handles HTTP and WebSocket traffic"
    - "Automated database backups configured with 30-day retention"
    - "Prometheus metrics endpoint is accessible and collecting data"
    - "Load test can be run via GitHub Actions or locally"
  artifacts:
    - path: "backend/locust/locustfile.py"
      provides: "Locust load test scenarios"
      contains: "class WorkOrderUser"
    - path: "backend/locust/locust_config.py"
      provides: "Locust configuration"
      contains: "TARGET_HOST"
    - path: "backend/requirements.txt"
      provides: "Locust dependency"
      contains: "locust"
    - path: "deployment/gunicorn.conf.py"
      provides: "Gunicorn production configuration"
      contains: "workers"
    - path: "deployment/nginx.conf"
      provides: "Nginx reverse proxy configuration"
      contains: "upstream django_backend"
    - path: "deployment/prometheus.yml"
      provides: "Prometheus scraping configuration"
      contains: "scrape_configs"
    - path: "deployment/scripts/backup.sh"
      provides: "Automated backup script"
      contains: "pg_dump"
    - path: ".github/workflows/load-test.yml"
      provides: "CI/CD load test workflow"
      contains: "locust"
  key_links:
    - from: "Locust tests"
      to: "Django API endpoints"
      via: "HTTP requests to /api/"
      pattern: "self\\.client\\.(get|post)"
    - from: "Nginx"
      to: "Gunicorn/Daphne"
      via: "upstream proxy_pass"
      pattern: "proxy_pass http://"
    - from: "Prometheus"
      to: "Django metrics"
      via: "/metrics/ endpoint"
      pattern: "/metrics/"
    - from: "Cron"
      to: "Backup script"
      via: "daily scheduled execution"
      pattern: "0 2 \\* \\* \\*"
---

<objective>
Implement load testing with Locust to verify system can handle 100 concurrent users with <500ms response time and <0.1% error rate. Configure production-ready deployment stack (Gunicorn + Daphne + Nginx), set up Prometheus monitoring, and implement automated database backups with 30-day retention.

Purpose: Load testing validates system performance before production. Production-ready deployment configuration ensures reliability, scalability, and maintainability. Monitoring enables proactive issue detection and capacity planning.

Output: Locust load test suite, production deployment configuration files, monitoring setup, automated backup scripts, and load test results showing system meets SLA requirements.
</objective>

<execution_context>
@/home/chenjiaxing/.claude/get-shit-done/workflows/execute-plan.md
@/home/chenjiaxing/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/10-production-hardening/10-CONTEXT.md
@.planning/phases/10-production-hardening/10-RESEARCH.md
@backend/config/settings.py
@backend/requirements.txt
@deployment/nginx.conf
</context>

<tasks>

<task type="auto">
  <name>Create Locust load test suite</name>
  <files>backend/locust/locustfile.py, backend/locust/locust_config.py</files>
  <action>
    Create a comprehensive Locust load test suite that simulates realistic user behavior:

    1. Create backend/locust directory:
    ```bash
    mkdir -p backend/locust
    ```

    2. Create backend/locust/__init__.py (empty file)

    3. Create backend/locust/locust_config.py:
    ```python
    """
    Locust configuration for load testing
    """
    import os

    # Target host for load testing
    # Use environment variable or default to localhost
    TARGET_HOST = os.environ.get('LOCUST_TARGET_HOST', 'http://localhost:8000')

    # Safety check to prevent accidental production testing
    if 'prod' in TARGET_HOST.lower():
        raise ValueError(
            "CANNOT LOAD TEST PRODUCTION! "
            "Use staging environment. "
            f"Current target: {TARGET_HOST}"
        )

    # Test credentials (should match test data setup)
    TEST_USERS = {
        'supervisor': {'username': 'test_supervisor', 'password': 'testpass123'},
        'operator': {'username': 'test_operator', 'password': 'testpass123'},
        'maker': {'username': 'test_maker', 'password': 'testpass123'},
    }

    # Load test targets
    TARGET_USERS = 100  # Number of concurrent users
    SPAWN_RATE = 10     # Users per second
    RUN_TIME = '5m'     # Test duration

    # SLA thresholds
    SLA_RESPONSE_TIME = 500  # ms
    SLA_ERROR_RATE = 0.001   # 0.1%
    SLA_P95_RESPONSE_TIME = 1000  # ms
    ```

    4. Create backend/locust/locustfile.py:
    ```python
    """
    Locust load test file for work order system
    Tests API endpoints under concurrent load
    """
    import random
    import json
    from locust import HttpUser, task, between, events
    from locust.runners import MasterRunner
    from locust_config import TARGET_HOST, TEST_USERS

    class CommonBehaviorMixin:
        """Common behaviors shared across user types"""

        def on_start(self):
            """Login when user starts"""
            self._login()

        def _login(self):
            """Authenticate and store token"""
            user_type = random.choice(['supervisor', 'operator', 'maker'])
            credentials = TEST_USERS[user_type]

            response = self.client.post('/api/auth/login/', json={
                'username': credentials['username'],
                'password': credentials['password']
            }, name='[Auth] Login')

            if response.status_code == 200:
                data = response.json()
                if 'token' in data:
                    self.token = data['token']
                    self.client.headers.update({
                        'Authorization': f'Token {self.token}'
                    })
                elif 'access' in data:
                    # JWT token format
                    self.token = data['access']
                    self.client.headers.update({
                        'Authorization': f'Bearer {self.token}'
                    })

        def _get_random_task_id(self):
            """Get a random task ID from the list"""
            response = self.client.get('/api/tasks/?page_size=1', name='[Tasks] Get random ID')
            if response.status_code == 200:
                results = response.json().get('results', [])
                if results:
                    return results[0]['id']
            return None

        def _get_random_workorder_id(self):
            """Get a random work order ID"""
            response = self.client.get('/api/workorders/?page_size=1', name='[WorkOrders] Get random ID')
            if response.status_code == 200:
                results = response.json().get('results', [])
                if results:
                    return results[0]['id']
            return None

    class WorkOrderUser(CommonBehaviorMixin, HttpUser):
        """
        Simulates a regular user working with work orders and tasks
        Most common operations with realistic weighting
        """

        wait_time = between(1, 5)  # Wait 1-5 seconds between tasks
        host = TARGET_HOST

        @task(5)
        def view_task_list(self):
            """View task list - most common operation (weight 5)"""
            filters = {}
            if random.random() < 0.3:
                filters['status'] = random.choice(['pending', 'in_progress', 'completed'])
            self.client.get('/api/tasks/', params=filters, name='[Tasks] List')

        @task(3)
        def view_workorder_list(self):
            """View work order list (weight 3)"""
            self.client.get('/api/workorders/', params={
                'page': random.randint(1, 3),
                'page_size': 20
            }, name='[WorkOrders] List')

        @task(2)
        def view_task_detail(self):
            """View task detail"""
            task_id = self._get_random_task_id()
            if task_id:
                self.client.get(f'/api/tasks/{task_id}/', name='[Tasks] Detail')

        @task(1)
        def view_notifications(self):
            """View notifications (weight 1)"""
            self.client.get('/api/notifications/', name='[Notifications] List')

        @task(1)
        def view_statistics(self):
            """View dashboard statistics"""
            self.client.get('/api/statistics/task_summary/', name='[Stats] Task Summary')

    class SupervisorUser(CommonBehaviorMixin, HttpUser):
        """
        Simulates supervisor with additional permissions
        Focuses on task assignment and department management
        """

        wait_time = between(2, 6)
        host = TARGET_HOST
        weight = 1  # Fewer supervisors than regular users

        @task(4)
        def view_department_tasks(self):
            """View department tasks"""
            departments = [1, 2, 3, 4, 5]
            dept_id = random.choice(departments)
            self.client.get('/api/tasks/', params={
                'assigned_department': dept_id,
                'status': 'pending'
            }, name='[Supervisor] Department Tasks')

        @task(3)
        def view_department_workload(self):
            """View department workload statistics"""
            self.client.get('/api/statistics/department_workload/', name='[Supervisor] Workload')

        @task(2)
        def assign_task(self):
            """Assign a task to operator (lower weight - write operation)"""
            # Get a pending task
            response = self.client.get('/api/tasks/', params={
                'status': 'pending',
                'page_size': 1
            }, name='[Supervisor] Get Pending Task')

            if response.status_code == 200:
                tasks = response.json().get('results', [])
                if tasks:
                    task_id = tasks[0]['id']
                    # Assign to random operator
                    operator_id = random.randint(1, 50)
                    self.client.post(f'/api/tasks/{task_id}/assign/', json={
                        'operator_id': operator_id
                    }, name='[Supervisor] Assign Task')

        @task(1)
        def view_dashboard(self):
            """View supervisor dashboard"""
            self.client.get('/api/statistics/collaboration/', name='[Supervisor] Dashboard')

    class OperatorUser(CommonBehaviorMixin, HttpUser):
        """
        Simulates operator focused on their tasks
        """

        wait_time = between(3, 8)
        host = TARGET_HOST
        weight = 1

        @task(5)
        def view_my_tasks(self):
            """View my assigned tasks"""
            self.client.get('/api/tasks/', params={
                'status': 'in_progress'
            }, name='[Operator] My Tasks')

        @task(3)
        def view_claimable_tasks(self):
            """View tasks I can claim"""
            self.client.get('/api/tasks/', params={
                'status': 'pending'
            }, name='[Operator] Claimable Tasks')

        @task(2)
        def update_task_progress(self):
            """Update task progress (write operation)"""
            task_id = self._get_random_task_id()
            if task_id:
                self.client.post(f'/api/tasks/{task_id}/update_progress/', json={
                    'quantity': random.randint(1, 100)
                }, name='[Operator] Update Progress')

        @task(1)
        def claim_task(self):
            """Claim an unassigned task"""
            response = self.client.get('/api/tasks/', params={
                'status': 'pending',
                'page_size': 1
            }, name='[Operator] Get Claimable')

            if response.status_code == 200:
                tasks = response.json().get('results', [])
                if tasks:
                    task_id = tasks[0]['id']
                    self.client.post(f'/api/tasks/{task_id}/claim/', name='[Operator] Claim Task')

    class MakerUser(CommonBehaviorMixin, HttpUser):
        """
        Simulates maker/sales user creating work orders
        """

        wait_time = between(5, 10)
        host = TARGET_HOST
        weight = 1

        @task(4)
        def view_my_workorders(self):
            """View work orders I created"""
            self.client.get('/api/workorders/', params={
                'page': random.randint(1, 5)
            }, name='[Maker] My WorkOrders')

        @task(1)
        def create_workorder(self):
            """Create a new work order (write operation)"""
            # Minimal work order data for testing
            self.client.post('/api/workorders/', json={
                'customer': 1,  # Assuming customer ID 1 exists
                'production_quantity': random.randint(100, 1000),
                'delivery_date': '2026-12-31',
                'priority': random.choice(['low', 'normal', 'high']),
            }, name='[Maker] Create WorkOrder')

        @task(2)
        def view_products(self):
            """View available products"""
            self.client.get('/api/products/', name='[Maker] Products List')

    @events.quitting.add_listener
    def on_quitting(environment, **kwargs):
        """
        Validate SLA compliance on quit.
        Exit with error code if SLAs are not met.
        """
        if isinstance(environment.runner, MasterRunner):
            return

        stats = environment.stats
        sla_passed = True

        print("\n" + "="*60)
        print("LOAD TEST RESULTS - SLA VALIDATION")
        print("="*60)

        # SLA 1: Average response time < 500ms
        avg_response_time = stats.total.avg_response_time
        print(f"\n1. Average Response Time: {avg_response_time:.0f}ms")
        print(f"   SLA Threshold: {500}ms")
        if avg_response_time > 500:
            print(f"   FAILED - Exceeds threshold by {avg_response_time - 500:.0f}ms")
            sla_passed = False
        else:
            print(f"   PASSED")

        # SLA 2: Error rate < 0.1%
        fail_ratio = stats.total.fail_ratio
        error_rate = fail_ratio * 100
        print(f"\n2. Error Rate: {error_rate:.3f}%")
        print(f"   SLA Threshold: 0.1%")
        if fail_ratio > 0.001:
            print(f"   FAILED - Exceeds threshold by {error_rate - 0.1:.3f}%")
            sla_passed = False
        else:
            print(f"   PASSED")

        # SLA 3: 95th percentile < 1000ms
        p95 = stats.total.get_response_time_percentile(0.95)
        print(f"\n3. 95th Percentile: {p95:.0f}ms")
        print(f"   SLA Threshold: 1000ms")
        if p95 > 1000:
            print(f"   FAILED - Exceeds threshold by {p95 - 1000:.0f}ms")
            sla_passed = False
        else:
            print(f"   PASSED")

        # RPS achieved
        rps = stats.total.total_rps
        print(f"\n4. Requests Per Second: {rps:.2f}")

        # Total requests
        total_requests = stats.total.num_requests
        print(f"5. Total Requests: {total_requests}")

        print("\n" + "="*60)
        if sla_passed:
            print("SLA VALIDATION: PASSED")
        else:
            print("SLA VALIDATION: FAILED")
            environment.process_exit_code = 1
        print("="*60 + "\n")
    ```

    5. Add Locust to requirements.txt:
    ```
    # Load Testing
    locust==2.18.3
    ```

    6. Install Locust:
    ```bash
    cd backend && pip install locust==2.18.3
    ```

    This creates a comprehensive load test suite with different user types and SLA validation.
  </action>
  <verify>
    cd backend && locust --version && python -c "from locust_config import TARGET_HOST; print(f'Target: {TARGET_HOST}')"
  </verify>
  <done>
    Locust is installed and load test configuration is created with SLA validation
  </done>
</task>

<task type="auto">
  <name>Create GitHub Actions workflow for load testing</name>
  <files>.github/workflows/load-test.yml</files>
  <action>
    Create a GitHub Actions workflow for automated load testing:

    1. Create .github/workflows directory:
    ```bash
    mkdir -p .github/workflows
    ```

    2. Create .github/workflows/load-test.yml:
    ```yaml
    name: Load Test

    on:
      push:
        branches: [ main, develop ]
        paths:
          - 'backend/**'
          - '.github/workflows/load-test.yml'
      pull_request:
        branches: [ main ]
        paths:
          - 'backend/**'
      workflow_dispatch:
        inputs:
          users:
            description: 'Number of users to simulate'
            required: true
            default: '50'
          spawn_rate:
            description: 'Users per second'
            required: true
            default: '10'
          run_time:
            description: 'Test duration'
            required: true
            default: '2m'

    jobs:
      load-test:
        name: Locust Load Test
        runs-on: ubuntu-latest

        services:
          postgres:
            image: postgres:14
            env:
              POSTGRES_DB: workorder_test
              POSTGRES_USER: workorder
              POSTGRES_PASSWORD: test_password
            options: >-
              --health-cmd pg_isready
              --health-interval 10s
              --health-timeout 5s
              --health-retries 5
            ports:
              - 5432:5432

          redis:
            image: redis:7-alpine
            options: >-
              --health-cmd "redis-cli ping"
              --health-interval 10s
              --health-timeout 5s
              --health-retries 5
            ports:
              - 6379:6379

        steps:
          - name: Checkout code
            uses: actions/checkout@v4

          - name: Set up Python
            uses: actions/setup-python@v4
            with:
              python-version: '3.11'

          - name: Cache pip packages
            uses: actions/cache@v3
            with:
              path: ~/.cache/pip
              key: ${{ runner.os }}-pip-${{ hashFiles('backend/requirements.txt') }}
              restore-keys: |
                ${{ runner.os }}-pip-

          - name: Install dependencies
            run: |
              cd backend
              pip install -r requirements.txt
              pip install locust

          - name: Run migrations
            env:
              DATABASE_URL: postgres://workorder:test_password@localhost:5432/workorder_test
              SECRET_KEY: test-secret-key-for-ci
              DEBUG: True
            run: |
              cd backend
              python manage.py migrate --noinput
              python manage.py loaddata ../backend/workorder/fixtures/initial_data.json

          - name: Create test data
            env:
              DATABASE_URL: postgres://workorder:test_password@localhost:5432/workorder_test
              SECRET_KEY: test-secret-key-for-ci
            run: |
              cd backend
              python -c "
              from django.contrib.auth import get_user_model
              from workorder.tests.factories import (
                  WorkOrderFactory, UserFactory, DepartmentFactory,
                  ProcessFactory, WorkOrderTaskFactory
              )
              import django
              django.setup()

              User = get_user_model()

              # Create test users
              supervisor = UserFactory(username='test_supervisor', role='supervisor')
              operator = UserFactory(username='test_operator', role='operator')
              maker = UserFactory(username='test_maker', role='maker')

              # Set passwords for token auth
              for user in [supervisor, operator, maker]:
                  user.set_password('testpass123')
                  user.save()

              # Create test data
              dept = DepartmentFactory(name='Test Dept')
              process = ProcessFactory(name='Test Process')

              for _ in range(50):
                  wo = WorkOrderFactory(approval_status='approved')
                  WorkOrderTaskFactory(
                      work_order=wo,
                      status='pending',
                      assigned_department=dept
                  )

              print('Test data created successfully')
              "

          - name: Start Django server
            env:
              DATABASE_URL: postgres://workorder:test_password@localhost:5432/workorder_test
              REDIS_URL: redis://localhost:6379/0
              SECRET_KEY: test-secret-key-for-ci
              DEBUG: False
            run: |
              cd backend
              gunicorn config.wsgi:application --bind 0.0.0.0:8000 --daemon --access-logfile - --error-logfile -
              # Wait for server to be ready
              sleep 5

          - name: Run Locust load test
            env:
              LOCUST_TARGET_HOST: http://localhost:8000
            run: |
              cd backend
              users=${{ github.event.inputs.users || '50' }}
              spawn_rate=${{ github.event.inputs.spawn_rate || '10' }}
              run_time=${{ github.event.inputs.run_time || '2m' }}

              locust -f locust/locustfile.py \
                --headless \
                --users $users \
                --spawn-rate $spawn_rate \
                --run-time $run_time \
                --host $LOCUST_TARGET_HOST \
                --html /tmp/locust-report.html \
                --csv /tmp/locust

          - name: Upload Locust report
            uses: actions/upload-artifact@v3
            with:
              name: locust-report
              path: |
                /tmp/locust-report.html
                /tmp/locust_stats.csv
                /tmp/locust_stats_history.csv
              retention-days: 30

          - name: Check SLA compliance
            run: |
              # Check if exit code was non-zero (SLA failed)
              if [ $? -ne 0 ]; then
                echo "::error::Load test SLA validation failed!"
                exit 1
              fi

          - name: Stop Django server
            if: always()
            run: |
              pkill -f gunicorn || true

      load-test-summary:
        name: Load Test Summary
        needs: load-test
        runs-on: ubuntu-latest
        if: always()
        steps:
          - name: Download artifacts
            uses: actions/download-artifact@v3
            with:
              name: locust-report

          - name: Print summary
            run: |
              echo "## Load Test Results" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "Detailed report available in artifacts." >> $GITHUB_STEP_SUMMARY
    ```

    3. Test the workflow by running locally with act:
    ```bash
    # Optional: Install act for local testing
    # brew install act  # macOS
    # or follow https://github.com/nektos/act for Linux

    # Run workflow locally
    act -j load-test
    ```

    This creates an automated load test that runs on push/PR and can be triggered manually.
  </action>
  <verify>
    ls -la .github/workflows/load-test.yml && cat .github/workflows/load-test.yml | grep -c "steps:"
  </verify>
  <done>
    GitHub Actions workflow created for automated load testing
  </done>
</task>

<task type="auto">
  <name>Configure production deployment stack</name>
  <files>backend/config/settings/production.py, deployment/gunicorn.conf.py, deployment/systemd/gunicorn.service, deployment/systemd/daphne.service, deployment/nginx.conf</files>
  <action>
    Create production-ready deployment configuration files:

    1. Create deployment directory structure:
    ```bash
    mkdir -p backend/deployment/{systemd,scripts}
    mkdir -p deployment
    ```

    2. Create backend/config/settings/production.py:
    ```python
    """
    Production settings for work order system
    """
    from .base import *
    import os

    # SECURITY
    DEBUG = False
    SECRET_KEY = os.environ.get('SECRET_KEY')
    if not SECRET_KEY:
        raise ValueError("SECRET_KEY environment variable must be set in production")

    ALLOWED_HOSTS = os.environ.get('ALLOWED_HOSTS', '').split(',')

    # Database - PostgreSQL
    DATABASES = {
        'default': {
            'ENGINE': 'django.db.backends.postgresql',
            'NAME': os.environ.get('POSTGRES_DB', 'workorder'),
            'USER': os.environ.get('POSTGRES_USER', 'workorder'),
            'PASSWORD': os.environ.get('POSTGRES_PASSWORD'),
            'HOST': os.environ.get('POSTGRES_HOST', 'localhost'),
            'PORT': os.environ.get('POSTGRES_PORT', '5432'),
            'OPTIONS': {
                'connect_timeout': 10,
                'sslmode': 'require',
            },
            'CONN_MAX_AGE': 600,
        }
    }

    # Cache - Redis
    CACHES = {
        'default': {
            'BACKEND': 'django.core.cache.backends.redis.RedisCache',
            'LOCATION': os.environ.get('REDIS_URL', 'redis://localhost:6379/0'),
            'OPTIONS': {
                'CLIENT_CLASS': 'django_redis.client.DefaultClient',
            },
            'KEY_PREFIX': 'workorder',
            'TIMEOUT': 300,
        }
    }

    # Channels - Redis for WebSocket
    CHANNEL_LAYERS = {
        'default': {
            'BACKEND': 'channels_redis.core.RedisChannelLayer',
            'CONFIG': {
                "hosts": [os.environ.get('REDIS_URL', 'redis://localhost:6379/0')],
                "symmetric_encryption_keys": [SECRET_KEY],
            },
        }
    }

    # Security settings
    SECURE_SSL_REDIRECT = True
    SESSION_COOKIE_SECURE = True
    CSRF_COOKIE_SECURE = True
    SECURE_HSTS_SECONDS = 31536000
    SECURE_HSTS_INCLUDE_SUBDOMAINS = True
    SECURE_HSTS_PRELOAD = True
    SECURE_BROWSER_XSS_FILTER = True
    SECURE_CONTENT_TYPE_NOSNIFF = True
    X_FRAME_OPTIONS = 'DENY'

    SECURE_PROXY_SSL_HEADER = ('HTTP_X_FORWARDED_PROTO', 'https')

    # Logging
    LOGGING = {
        'version': 1,
        'disable_existing_loggers': False,
        'formatters': {
            'verbose': {
                'format': '{levelname} {asctime} {module} {process:d} {thread:d} {message}',
                'style': '{',
            },
            'simple': {
                'format': '{levelname} {asctime} {module} {message}',
                'style': '{',
            },
        },
        'filters': {
            'require_debug_false': {
                '()': 'django.utils.log.RequireDebugFalse',
            },
        },
        'handlers': {
            'file': {
                'level': 'INFO',
                'class': 'logging.handlers.RotatingFileHandler',
                'filename': '/var/log/django/workorder.log',
                'maxBytes': 1024*1024*50,  # 50 MB
                'backupCount': 10,
                'formatter': 'verbose',
            },
            'error_file': {
                'level': 'ERROR',
                'class': 'logging.handlers.RotatingFileHandler',
                'filename': '/var/log/django/workorder_error.log',
                'maxBytes': 1024*1024*50,
                'backupCount': 10,
                'formatter': 'verbose',
            },
        },
        'loggers': {
            'django': {
                'handlers': ['file', 'error_file'],
                'level': 'WARNING',
                'propagate': False,
            },
            'workorder': {
                'handlers': ['file', 'error_file'],
                'level': 'INFO',
                'propagate': False,
            },
        },
    }

    # Email for error notifications
    if os.environ.get('EMAIL_HOST'):
        EMAIL_HOST = os.environ.get('EMAIL_HOST')
        EMAIL_PORT = int(os.environ.get('EMAIL_PORT', 587))
        EMAIL_HOST_USER = os.environ.get('EMAIL_HOST_USER')
        EMAIL_HOST_PASSWORD = os.environ.get('EMAIL_HOST_PASSWORD')
        EMAIL_USE_TLS = True
        ADMINS = [('Admin', os.environ.get('ADMIN_EMAIL'))]
        MANAGERS = ADMINS
    ```

    3. Create deployment/gunicorn.conf.py:
    ```python
    """
    Gunicorn configuration for production
    """
    import multiprocessing
    import os

    # Server socket
    bind = os.environ.get('GUNICORN_BIND', '127.0.0.1:8000')
    backlog = 2048

    # Worker processes
    # Formula: (2 x CPU cores) + 1
    workers = int(os.environ.get('GUNICORN_WORKERS', (2 * multiprocessing.cpu_count()) + 1))
    worker_class = 'sync'
    worker_connections = 1000
    max_requests = 1000  # Restart workers after N requests to prevent memory leaks
    max_requests_jitter = 100  # Randomize restarts
    timeout = 30
    keepalive = 2

    # Process naming
    proc_name = 'workorder_backend'

    # Logging
    accesslog = '/var/log/gunicorn/access.log'
    errorlog = '/var/log/gunicorn/error.log'
    loglevel = 'info'
    access_log_format = '%(h)s %(l)s %(u)s %(t)s "%(r)s" %(s)s %(b)s "%(f)s" "%(a)s" %(D)s'

    # Process management
    daemon = False  # Let systemd manage
    pidfile = '/var/run/gunicorn/gunicorn.pid'
    user = os.environ.get('GUNICORN_USER', 'www-data')
    group = os.environ.get('GUNICORN_GROUP', 'www-data')
    umask = 007

    # Server hooks
    def post_fork(server, worker):
        server.log.info(f'Worker spawned (pid: {worker.pid})')

    def pre_exec(server):
        server.log.info('Forked child, re-executing.')

    def when_ready(server):
        server.log.info('Server is ready. Spawning workers')

    def worker_int(worker):
        worker.log.info(f'Worker received INT or QUIT signal (pid: {worker.pid})')

    def on_exit(server):
        server.log.info('Server is stopping')
    ```

    4. Create deployment/systemd/gunicorn.service:
    ```ini
    [Unit]
    Description=Workorder Gunicorn Daemon
    After=network.target postgresql.service

    [Service]
    Type=notify
    User=workorder
    Group=workorder
    RuntimeDirectory=gunicorn
    WorkingDirectory=/opt/workorder/backend
    Environment="PATH=/opt/workorder/backend/venv/bin"
    EnvironmentFile=/opt/workorder/backend/.env
    ExecStart=/opt/workorder/backend/venv/bin/gunicorn --config deployment/gunicorn.conf.py config.wsgi:application
    ExecReload=/bin/kill -s HUP $MAINPID
    KillMode=mixed
    TimeoutStopSec=30
    PrivateTmp=true
    Restart=always
    RestartSec=5

    # Security
    NoNewPrivileges=true
    PrivateTmp=true

    [Install]
    WantedBy=multi-user.target
    ```

    5. Create deployment/systemd/daphne.service:
    ```ini
    [Unit]
    Description=Workorder Daphne WebSocket Daemon
    After=network.target gunicorn.service redis.service

    [Service]
    Type=notify
    User=workorder
    Group=workorder
    RuntimeDirectory=daphne
    WorkingDirectory=/opt/workorder/backend
    Environment="PATH=/opt/workorder/backend/venv/bin"
    EnvironmentFile=/opt/workorder/backend/.env
    ExecStart=/opt/workorder/backend/venv/bin/daphne -b 127.0.0.1 -p 8001 config.asgi:application
    ExecReload=/bin/kill -s HUP $MAINPID
    KillMode=mixed
    TimeoutStopSec=30
    PrivateTmp=true
    Restart=always
    RestartSec=5

    [Install]
    WantedBy=multi-user.target
    ```

    6. Create deployment/nginx.conf:
    ```nginx
    # Upstream servers
    upstream django_backend {
        least_conn;
        server 127.0.0.1:8000 max_fails=3 fail_timeout=30s;
    }

    upstream daphne_websocket {
        server 127.0.0.1:8001;
    }

    # Rate limiting zone
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=10r/s;
    limit_conn_zone $binary_remote_addr zone=conn_limit:10m;

    # HTTP to HTTPS redirect
    server {
        listen 80;
        server_name _;
        return 301 https://$host$request_uri;
    }

    # HTTPS server
    server {
        listen 443 ssl http2;
        server_name _;

        # SSL configuration (use Let's Encrypt)
        ssl_certificate /etc/ssl/certs/workorder.crt;
        ssl_certificate_key /etc/ssl/private/workorder.key;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers 'ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384';
        ssl_prefer_server_ciphers on;

        # Security headers
        add_header X-Frame-Options "SAMEORIGIN" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;

        # Client limits
        client_max_body_size 100M;
        limit_conn conn_limit 20;

        # Static files
        location /static/ {
            alias /opt/workorder/backend/staticfiles/;
            expires 30d;
            add_header Cache-Control "public, immutable";
            access_log off;
        }

        # Media files
        location /media/ {
            alias /opt/workorder/backend/media/;
            expires 7d;
        }

        # API endpoints with rate limiting
        location /api/ {
            limit_req zone=api_limit burst=20 nodelay;

            proxy_pass http://django_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_redirect off;

            proxy_connect_timeout 60s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
        }

        # WebSocket (Daphne)
        location /ws/ {
            proxy_pass http://daphne_websocket;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # WebSocket timeouts
            proxy_connect_timeout 7d;
            proxy_send_timeout 7d;
            proxy_read_timeout 7d;
        }

        # Health check endpoint
        location /health/ {
            access_log off;
            return 200 "healthy";
            add_header Content-Type text/plain;
        }

        # Frontend (Vue.js SPA)
        location / {
            root /var/www/workorder;
            try_files $uri $uri/ /index.html;
        }
    }
    ```

    This creates a complete production deployment stack configuration.
  </action>
  <verify>
    ls -la deployment/ backend/deployment/ backend/config/settings/production.py
  </verify>
  <done>
    Production deployment configuration files created for Gunicorn, Daphne, Nginx, and systemd
  </done>
</task>

<task type="auto">
  <name>Set up monitoring and automated backups</name>
  <files>deployment/prometheus.yml, deployment/scripts/backup.sh, deployment/crontab/backup, backend/config/settings/production.py</files>
  <action>
    Set up Prometheus monitoring and automated database backups:

    1. Add django-prometheus to requirements.txt:
    ```
    # Monitoring
    django-prometheus==2.3.1
    prometheus-client==0.20.0
    ```

    2. Update backend/config/settings/production.py to add monitoring:
    ```python
    # Add to INSTALLED_APPS
    INSTALLED_APPS = [
        # ... existing apps ...
        'django_prometheus',
    ]

    # Add to MIDDLEWARE (at beginning and end)
    MIDDLEWARE = [
        'django_prometheus.middleware.PrometheusBeforeMiddleware',
        # ... existing middleware ...
        'django_prometheus.middleware.PrometheusAfterMiddleware',
    ]
    ```

    3. Update backend/config/urls.py to add metrics endpoint:
    ```python
    from django.urls import path, include

    urlpatterns = [
        # ... existing patterns ...
        # Metrics endpoint (protect with authentication in production!)
        path('metrics/', include('django_prometheus.urls')),
    ]
    ```

    4. Create deployment/prometheus.yml:
    ```yaml
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
      external_labels:
        monitor: 'workorder-monitor'

    scrape_configs:
      # Django application
      - job_name: 'django'
        static_configs:
          - targets: ['localhost:8000']
        metrics_path: '/metrics/'

      # Gunicorn (if using prometheus exporter)
      - job_name: 'gunicorn'
        static_configs:
          - targets: ['localhost:8000']
        metrics_path: '/metrics/'

      # Node exporter (system metrics)
      - job_name: 'node'
        static_configs:
          - targets: ['localhost:9100']

      # Postgres exporter
      - job_name: 'postgres'
        static_configs:
          - targets: ['localhost:9187']

      # Redis exporter
      - job_name: 'redis'
        static_configs:
          - targets: ['localhost:9121']
    ```

    5. Create deployment/scripts/backup.sh:
    ```bash
    #!/bin/bash
    #
    # Automated backup script for workorder system
    # Backs up database and media files daily
    #

    set -e

    # Configuration
    BACKUP_DIR="/var/backups/workorder"
    DATE=$(date +%Y%m%d_%H%M%S)
    RETENTION_DAYS=30

    # Load environment variables
    if [ -f /opt/workorder/backend/.env ]; then
        source /opt/workorder/backend/.env
    fi

    # Create backup directory
    mkdir -p "$BACKUP_DIR"

    echo "[$(date)] Starting backup..."

    # Database backup
    echo "[$(date)] Backing up database..."
    PGPASSWORD="$POSTGRES_PASSWORD" pg_dump \
        -h "${POSTGRES_HOST:-localhost}" \
        -U "${POSTGRES_USER:-workorder}" \
        -d "${POSTGRES_DB:-workorder}" \
        --no-owner --no-acl | gzip > "$BACKUP_DIR/db_$DATE.sql.gz"

    # Verify database backup
    if [ $? -eq 0 ]; then
        SIZE=$(du -h "$BACKUP_DIR/db_$DATE.sql.gz" | cut -f1)
        echo "[$(date)] Database backup completed: $SIZE"
    else
        echo "[$(date)] ERROR: Database backup failed!"
        exit 1
    fi

    # Media files backup
    echo "[$(date)] Backing up media files..."
    if [ -d /opt/workorder/backend/media ]; then
        tar -czf "$BACKUP_DIR/media_$DATE.tar.gz" -C /opt/workorder/backend media
        SIZE=$(du -h "$BACKUP_DIR/media_$DATE.tar.gz" | cut -f1)
        echo "[$(date)] Media backup completed: $SIZE"
    fi

    # Static files backup (optional - can be regenerated)
    # tar -czf "$BACKUP_DIR/static_$DATE.tar.gz" -C /opt/workorder/backend staticfiles

    # Remove old backups
    echo "[$(date)] Cleaning up old backups (older than $RETENTION_DAYS days)..."
    find "$BACKUP_DIR" -name "db_*.sql.gz" -mtime +$RETENTION_DAYS -delete
    find "$BACKUP_DIR" -name "media_*.tar.gz" -mtime +$RETENTION_DAYS -delete

    # List current backups
    echo "[$(date)] Current backups:"
    ls -lh "$BACKUP_DIR/" | tail -10

    echo "[$(date)] Backup completed successfully!"

    # Optional: Upload to cloud storage
    # aws s3 sync "$BACKUP_DIR/" s3://workorder-backups/

    # Optional: Send notification
    # if command -v mail &> /dev/null; then
    #     echo "Backup completed at $(date)" | mail -s "Workorder Backup" admin@example.com
    # fi
    ```

    6. Create deployment/crontab/backup:
    ```
    # Workorder system automated backups
    # Run daily at 2:00 AM

    0 2 * * * /opt/workorder/backend/deployment/scripts/backup.sh >> /var/log/backup.log 2>&1
    ```

    7. Install monitoring exporters (Ubuntu/Debian):
    ```bash
    # Node exporter (system metrics)
    sudo apt install prometheus-node-exporter

    # Postgres exporter
    sudo apt install prometheus-postgres-exporter

    # Redis exporter
    wget https://github.com/oliver006/redis_exporter/releases/download/v1.52.0/redis_exporter-v1.52.0.linux-amd64.tar.gz
    tar xvfz redis_exporter-*.tar.gz
    sudo cp redis_exporter /usr/local/bin/
    ```

    8. Create systemd service for Redis exporter:
    Create /etc/systemd/system/redis_exporter.service:
    ```ini
    [Unit]
    Description=Redis Exporter
    After=network.target

    [Service]
    Type=simple
    User=prometheus
    ExecStart=/usr/local/bin/redis_exporter --web.listen-address=:9121

    [Install]
    WantedBy=multi-user.target
    ```

    9. Make backup script executable and set up cron:
    ```bash
    chmod +x deployment/scripts/backup.sh
    sudo mkdir -p /var/backups/workorder
    sudo chown workorder:workorder /var/backups/workorder

    # Install cron job
    sudo cp deployment/crontab/backup /etc/cron.d/workorder-backup
    sudo chmod 644 /etc/cron.d/workorder-backup
    sudo service cron reload
    ```

    This sets up comprehensive monitoring and automated backup infrastructure.
  </action>
  <verify>
    ls -la deployment/prometheus.yml deployment/scripts/backup.sh && cat deployment/scripts/backup.sh | grep -c "pg_dump"
  </verify>
  <done>
    Prometheus monitoring configured and automated backup scripts created
  </done>
</task>

<task type="auto">
  <name>Run load tests and validate SLA compliance</name>
  <files>backend/locust/</files>
  <action>
    Run the Locust load tests and verify the system meets SLA requirements:

    1. First, ensure the development server is running with test data:
    ```bash
    cd backend

    # Start Redis (if not running)
    redis-server --daemonize yes

    # Start Django development server
    python manage.py runserver 8000
    ```

    2. In a new terminal, run Locust with headless mode:
    ```bash
    cd backend

    # Run load test with 100 users, 10 spawn rate, 5 minutes
    locust -f locust/locustfile.py \
        --headless \
        --users 100 \
        --spawn-rate 10 \
        --run-time 5m \
        --host http://localhost:8000 \
        --html load-test-report.html \
        --csv load-test-results
    ```

    3. Or run with the Web UI for interactive testing:
    ```bash
    locust -f locust/locustfile.py --host http://localhost:8000

    # Then open http://localhost:8089 in browser
    # Set users to 100, spawn rate to 10, start test
    ```

    4. Review the test results. The test will automatically validate SLA compliance:
    - Average response time < 500ms
    - Error rate < 0.1%
    - 95th percentile < 1000ms

    5. If SLA fails, investigate:
    - Check response times by endpoint in the report
    - Identify slow endpoints and optimize queries
    - Check for N+1 query problems
    - Add database indexes if needed
    - Verify caching is working

    6. Create a summary script backend/run_load_test.sh:
    ```bash
    #!/bin/bash
    #
    # Load test execution script
    #

    set -e

    echo "========================================"
    echo "Work Order System - Load Test"
    echo "========================================"
    echo ""

    # Configuration
    USERS=${1:-100}
    SPAWN_RATE=${2:-10}
    RUN_TIME=${3:-5m}
    HOST=${4:-http://localhost:8000}

    echo "Configuration:"
    echo "  Users: $USERS"
    echo "  Spawn Rate: $SPAWN_RATE users/sec"
    echo "  Run Time: $RUN_TIME"
    echo "  Target Host: $HOST"
    echo ""

    # Safety check
    if [[ "$HOST" == *"prod"* ]]; then
        echo "ERROR: Cannot run load test against production!"
        exit 1
    fi

    # Create results directory
    mkdir -p backend/load-test-results
    cd backend

    # Check if server is running
    echo "Checking if server is running..."
    if ! curl -sSf "$HOST/api/" > /dev/null 2>&1; then
        echo "ERROR: Server is not responding at $HOST"
        echo "Please start the server first:"
        echo "  python manage.py runserver 8000"
        exit 1
    fi
    echo "Server is running."
    echo ""

    # Run load test
    echo "Starting load test..."
    locust -f locust/locustfile.py \
        --headless \
        --users "$USERS" \
        --spawn-rate "$SPAWN_RATE" \
        --run-time "$RUN_TIME" \
        --host "$HOST" \
        --html load-test-results/report.html \
        --csv load-test-results/results

    EXIT_CODE=$?

    echo ""
    echo "========================================"
    echo "Load Test Complete"
    echo "========================================"
    echo ""
    echo "Results saved to:"
    echo "  - backend/load-test-results/report.html (HTML report)"
    echo "  - backend/load-test-results/results*.csv (Raw data)"
    echo ""

    if [ $EXIT_CODE -eq 0 ]; then
        echo "SLA Validation: PASSED"
    else
        echo "SLA Validation: FAILED"
        echo ""
        echo "Please review the HTML report for details."
    fi

    exit $EXIT_CODE
    ```

    7. Make the script executable:
    ```bash
    chmod +x backend/run_load_test.sh
    ```

    8. To run the test, use:
    ```bash
    ./backend/run_load_test.sh 100 10 5m http://localhost:8000
    ```

    9. After the test completes, review the HTML report:
    ```bash
    # Open in browser (macOS)
    open backend/load-test-results/report.html

    # Linux
    xdg-open backend/load-test-results/report.html
    ```

    10. Record baseline metrics:
    - Average response time
    - Requests per second
    - Error rate
    - 95th percentile

    This provides a validated load test result showing the system meets production SLA requirements.
  </action>
  <verify>
    ls -la backend/load-test-results/report.html && cat backend/run_load_test.sh | grep -c "SLA"
  </verify>
  <done>
    Load test executed and SLA validation passed with report generated
  </done>
</task>

</tasks>

<verification>
After completing all tasks, verify:

1. Locust load test runs successfully without errors
2. Load test report shows SLA compliance (500ms, 0.1% error rate)
3. Gunicorn and Daphne configuration files are valid
4. Nginx configuration passes syntax check (nginx -t)
5. Backup script is executable and produces backups
6. Prometheus configuration is valid
7. GitHub Actions workflow file is valid YAML
8. Load test results are saved and viewable
</verification>

<success_criteria>
- Locust load test simulates 100+ concurrent users
- API response times < 500ms at target load
- Error rate < 0.1% during load test
- Production deployment configuration complete (Gunicorn, Daphne, Nginx, systemd)
- Automated backup script configured with cron
- Prometheus monitoring configured
- Load test report generated showing SLA compliance
- GitHub Actions workflow for CI/CD load testing
</success_criteria>

<output>
After completion, create `.planning/phases/10-production-hardening/10-03-SUMMARY.md` with:
- Load test results (RPS, response time, error rate)
- SLA compliance status
- Deployment configuration files created
- Backup and monitoring setup summary
</output>
